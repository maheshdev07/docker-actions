name: GST Scraper CI/CD

# Trigger conditions
on:
  # Run on push to main branch
  push:
    branches: [ main ]
  
  # Run on pull request
  pull_request:
    branches: [ main ]
  
  # Schedule: Run daily at 9 AM IST (3:30 AM UTC)
  schedule:
    - cron: '30 3 * * *'
  
  # Allow manual trigger
  workflow_dispatch:

# Environment variables
env:
  DOCKER_IMAGE: ${{ secrets.DOCKERHUB_USERNAME || 'maheshdev07' }}/gst-scraper
  PYTHON_VERSION: '3.11'

jobs:
  # Job 1: Run tests and linting
  test:
    name: Test Python Code
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest flake8
      
      - name: Lint with flake8
        run: |
          # Stop on errors, ignore line length
          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics
          # Treat warnings as errors (optional)
          # flake8 src/ --count --exit-zero --max-complexity=10 --statistics
      
      - name: Run tests (if any)
        run: |
          # Add your tests here
          echo "No tests defined yet"
          # pytest tests/

  # Job 2: Build and test Docker image
  build-docker:
    name: Build Docker Image
    needs: test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          load: true
          tags: gst-scraper:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Test Docker image
        run: |
          mkdir -p data logs
          chmod -R 777 data logs
          docker run --rm \
            -v $(pwd)/data:/app/data \
            -v $(pwd)/logs:/app/logs \
            gst-scraper:test
      
      - name: Upload scraping results
        uses: actions/upload-artifact@v4
        with:
          name: gst-data
          path: |
            data/*.csv
            data/*.json
            logs/*.log
          retention-days: 7

  # Job 3: Run scraper and save results
  scrape:
    name: Run GST Scraper
    needs: build-docker
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Create directories
        run: |
          mkdir -p data logs
      
      - name: Run scraper
        run: |
          python src/scraper.py
        env:
          DEBUG: true
      
      - name: Display results
        run: |
          echo "=== Scraped Data Files ==="
          ls -lh data/
          echo ""
          echo "=== CSV Preview ==="
          head -20 data/*.csv || echo "No CSV files"
          echo ""
          echo "=== Log Summary ==="
          tail -50 logs/*.log || echo "No log files"
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: gst-scraper-results-${{ github.run_number }}
          path: |
            data/
            logs/
          retention-days: 30
      
      - name: Generate summary
        run: |
          echo "## GST Scraping Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow Run:** #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered by:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp:** $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Files Generated:" >> $GITHUB_STEP_SUMMARY
          ls -lh data/ | tail -n +2 >> $GITHUB_STEP_SUMMARY

  # Job 4: Build and push to Docker Hub
  push-docker:
    name: Push to Docker Hub
    needs: scrape
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ env.DOCKER_IMAGE }}:latest
            ${{ env.DOCKER_IMAGE }}:${{ github.run_number }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Docker Hub Description
        uses: peter-evans/dockerhub-description@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
          repository: ${{ env.DOCKER_IMAGE }}
          short-description: "Automated GST portal scraper"
          readme-filepath: ./README.md
